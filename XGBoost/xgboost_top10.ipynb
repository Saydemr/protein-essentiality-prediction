{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f29d961a-9852-4649-ba07-f2653026bbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score, make_scorer, f1_score, matthews_corrcoef\n",
    "from sklearn.model_selection import RandomizedSearchCV,  GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd8c2333-ecda-418b-8af0-23386ab8018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = [\"emb/sc_ppi_emb_d32_e1_l120_w20_k10_p1\", \"emb/sc_ppi_emb_d32_e3_l120_w10_k10_p2\",\n",
    "          \"emb/sc_ppi_emb_d32_e3_l80_w20_k10_p0.5\", \"emb/sc_ppi_emb_d32_e3_l80_w20_k10_p1\", \n",
    "          \"emb/sc_ppi_emb_d64_e1_l120_w20_k10_p1\", \"emb/sc_ppi_emb_d64_e3_l120_w10_k10_p1\",\n",
    "          \"emb/sc_ppi_emb_d64_e3_l120_w20_k20_p2\", \"emb/sc_ppi_emb_d64_e3_l80_w10_k10_p2\",\n",
    "          \"emb/sc_ppi_emb_d64_e3_l80_w20_k10_p0.5\", \"emb/sc_ppi_emb_d64_e3_l80_w20_k20_p0.5\"]\n",
    "fill = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8fc1c69-654e-43d0-a620-1aac44b732ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embeddings</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy Score</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Matthews Correlation Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>emb/sc_ppi_emb_d32_e1_l120_w20_k10_p1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>emb/sc_ppi_emb_d32_e3_l120_w10_k10_p2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emb/sc_ppi_emb_d32_e3_l80_w20_k10_p0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emb/sc_ppi_emb_d32_e3_l80_w20_k10_p1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emb/sc_ppi_emb_d64_e1_l120_w20_k10_p1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Embeddings  Accuracy  Balanced Accuracy Score  \\\n",
       "0   emb/sc_ppi_emb_d32_e1_l120_w20_k10_p1         0                        0   \n",
       "1   emb/sc_ppi_emb_d32_e3_l120_w10_k10_p2         0                        0   \n",
       "2  emb/sc_ppi_emb_d32_e3_l80_w20_k10_p0.5         0                        0   \n",
       "3    emb/sc_ppi_emb_d32_e3_l80_w20_k10_p1         0                        0   \n",
       "4   emb/sc_ppi_emb_d64_e1_l120_w20_k10_p1         0                        0   \n",
       "\n",
       "   F1 Score  Matthews Correlation Coefficient  \n",
       "0         0                                 0  \n",
       "1         0                                 0  \n",
       "2         0                                 0  \n",
       "3         0                                 0  \n",
       "4         0                                 0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(embeds[0]+\"_out.csv\")\n",
    "#s = embeds[0]+\"_out.csv\"\n",
    "#m = pd.read_csv(s)\n",
    "#m.head()\n",
    "data = {'Embeddings': embeds,\n",
    "        'Accuracy': fill,\n",
    "        'Balanced Accuracy Score': fill,\n",
    "        'F1 Score': fill,\n",
    "        'Matthews Correlation Coefficient': fill\n",
    "        }\n",
    "results = pd.DataFrame(data, columns= ['Embeddings', 'Accuracy', 'Balanced Accuracy Score', 'F1 Score', 'Matthews Correlation Coefficient'])\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cbf28f0-2839-4cc8-80ff-02df68d1c3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embeddings</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy Score</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Matthews Correlation Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Embeddings, Accuracy, Balanced Accuracy Score, F1 Score, Matthews Correlation Coefficient]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns= ['Embeddings', 'Accuracy', 'Balanced Accuracy Score', 'F1 Score', 'Matthews Correlation Coefficient'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da62f123-f78d-4cda-af78-1a53c0fc7252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:07:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:07:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:07:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:07:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:07:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:07:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:07:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:07:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:07:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:07:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "for x in embeds:\n",
    "    X = pd.read_csv(x+\".emb.csv\")\n",
    "    X.drop(columns=X.columns[0], axis=1, inplace=True)\n",
    "    y = pd.read_csv(x+\".emb_out.csv\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "    param_grid = {\n",
    "         'max_depth': [5, 6, 7],\n",
    "         'learning_rate': [0.2, 0.15, 0.1],\n",
    "         'min_child_weight' : [1, 3, 5],\n",
    "         'gamma': [1.0, 2.0, 3.0],\n",
    "         'reg_lambda': [10.0, 20.0, 100.0],\n",
    "         'scale_pos_weight': [1]\n",
    "    }\n",
    "\n",
    "    clf = GridSearchCV(estimator = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                                                              seed=42,\n",
    "                                                              subsample=0.9,\n",
    "                                                              colsample_bytree=0.5\n",
    "                                                               ),\n",
    "                                                              param_grid = param_grid,\n",
    "                                                              scoring = 'roc_auc',\n",
    "                                                              verbose = 2,\n",
    "                                                              n_jobs = 10,\n",
    "                                                              cv = 4)\n",
    "\n",
    "    clf.fit(X_train,\n",
    "            y_train,\n",
    "            early_stopping_rounds=10,\n",
    "            eval_metric='auc',\n",
    "            eval_set=[(X_test, y_test)],\n",
    "            verbose=True)\n",
    "\n",
    "\n",
    "    print(clf.best_estimator_)\n",
    "    print(clf.best_params_)\n",
    "    \n",
    "    predictions = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    balanced_acc = balanced_accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    matt = matthews_corrcoef(y_test, predictions)\n",
    "    row = [x, acc, balanced_acc, f1, matt]\n",
    "    df.loc[x] = row\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c4c05-45c8-4f27-8c3b-5e61479de4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "np.savetxt(\"results.txt\", df, fmt='%s', header='embed acc bal_acc f1 matt_corr', comments='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
